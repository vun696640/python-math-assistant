import os
import json
from typing import List, Dict

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from pypdf import PdfReader
from openai import OpenAI
client = OpenAI()
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

AI_MODELS = [
    # T·∫°m th·ªùi b·ªè gpt-4o-mini xu·ªëng cu·ªëi ƒë·ªÉ n√≥ ƒë·ª° ƒÉn rate limit tr∆∞·ªõc
    "gpt-4o",        # ∆∞u ti√™n 1
    "o3-mini",       # ∆∞u ti√™n 2
    "o1-mini",       # ∆∞u ti√™n 3
    "gpt-4o-mini",   # ƒë·ªÉ cu·ªëi c√πng
]

def ask_ai(messages):
    """
    G·ªçi OpenAI v·ªõi danh s√°ch fallback model.
    Tr·∫£ v·ªÅ string reply. N·∫øu t·∫•t c·∫£ model l·ªói th√¨ tr·∫£ v·ªÅ message l·ªói m·ªÅm.
    """
    last_error = None

    for model in AI_MODELS:
        try:
            print(f"üëâ ƒêang g·ªçi model: {model}")
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=1500,
            )
            # SDK m·ªõi: d√πng .content ch·ª© kh√¥ng index ki·ªÉu dict
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"‚ùå Model {model} failed, trying next‚Ä¶ ({e})")
            last_error = e
            continue

    # N·∫øu t·∫•t c·∫£ ƒë·ªÅu l·ªói
    return (
        "Hi·ªán t·∫°i h·ªá th·ªëng AI ƒëang b·ªã qu√° t·∫£i (rate limit) n√™n m√¨nh ch∆∞a tr·∫£ l·ªùi ƒë∆∞·ª£c.\n\n"
        f"(Chi ti·∫øt k·ªπ thu·∫≠t: {last_error})"
    )


# ========================
#  PATHS & CONFIG
# ========================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))


def _find_chuan_dau_ra_file() -> str:
    """
    T√¨m file chu·∫©n ƒë·∫ßu ra: ∆∞u ti√™n 'chuan_dau_ra.md', n·∫øu kh√¥ng c√≥ th√¨ 'chuan_dau_ra'.
    """
    candidates = ["chuan_dau_ra.md", "chuan_dau_ra"]
    for name in candidates:
        path = os.path.join(BASE_DIR, name)
        if os.path.exists(path):
            return path
    # fallback: c·ª© tr·∫£ v·ªÅ .md, nh∆∞ng parse s·∫Ω d√πng b·ªô m·∫∑c ƒë·ªãnh
    return os.path.join(BASE_DIR, candidates[0])


CHUAN_DAU_RA_FILE = _find_chuan_dau_ra_file()
INDEX_FILE = os.path.join(BASE_DIR, "index.html")

app = FastAPI(title="K9 Math AI Assistant")

# Serve static (js/pdf/font, ‚Ä¶)
static_dir = os.path.join(BASE_DIR, "static")
if os.path.isdir(static_dir):
    app.mount("/static", StaticFiles(directory=static_dir), name="static")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI client (SDK m·ªõi)
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# ========================
#  DATA MODELS
# ========================
class ChatMessage(BaseModel):
    role: str
    content: str


class ChatRequest(BaseModel):
    messages: List[ChatMessage]


class ChatResponse(BaseModel):
    reply: str
    standards: List[str]


class Standard(BaseModel):
    code: str
    name: str
    description: str


class ClassifyRequest(BaseModel):
    text: str


class ClassifyResponse(BaseModel):
    standards: List[str]


class QuizQuestion(BaseModel):
    id: int
    text: str
    options: List[str]
    correct_index: int
    standards: List[str]


class QuizResponse(BaseModel):
    questions: List[QuizQuestion]


# ========================
#  QUIZ CACHE (TR√ÅNH SINH ƒê·ªÄ M·ªöI NGO√ÄI √ù MU·ªêN)
# ========================
# Cache ƒë·ªÅ theo mode tr√™n lifetime c·ªßa process.
# L∆∞u √Ω: cache n√†y d√πng chung cho t·∫•t c·∫£ ng∆∞·ªùi d√πng ‚Äì nh∆∞ng v·ªõi b√†i test demo l√† ok.
QUIZ_CACHE: Dict[str, List[QuizQuestion]] = {
    "input": [],
    "output": [],
}

# ========================
#  CHU·∫®N ƒê·∫¶U RA T1‚ÄìT15
# ========================
def default_standards() -> Dict[str, Standard]:
    names = {
        "T1": "S·ªë & l≈©y th·ª´a",
        "T2": "T·ªâ l·ªá & ph·∫ßn trƒÉm",
        "T3": "G√≥c & tam gi√°c",
        "T4": "CƒÉn b·∫≠c hai",
        "T5": "Ph∆∞∆°ng tr√¨nh b·∫≠c nh·∫•t",
        "T6": "H·ªá ph∆∞∆°ng tr√¨nh",
        "T7": "B·∫•t ph∆∞∆°ng tr√¨nh",
        "T8": "H√†m s·ªë & ƒë·ªì th·ªã",
        "T9": "Tam gi√°c vu√¥ng & ƒë·ªãnh l√Ω Pythagore",
        "T10": "ƒê∆∞·ªùng tr√≤n",
        "T11": "Ti·∫øp tuy·∫øn",
        "T12": "H√¨nh tr·ª•, n√≥n, c·∫ßu",
        "T13": "Th·ªëng k√™",
        "T14": "X√°c su·∫•t",
        "T15": "B√†i to√°n th·ª±c t·∫ø",
    }
    return {
        code: Standard(
            code=code,
            name=name,
            description=f"Chu·∫©n {code} ‚Äì {name}. (M·∫∑c ƒë·ªãnh, d√πng khi thi·∫øu file chuan_dau_ra.)",
        )
        for code, name in names.items()
    }


def parse_chuan_dau_ra_md(path: str) -> Dict[str, Standard]:
    """
    ƒê·ªçc file chu·∫©n ƒë·∫ßu ra d·∫°ng markdown (## T1 ‚Äì ...).
    N·∫øu file kh√¥ng t·ªìn t·∫°i ho·∫∑c r·ªóng, tr·∫£ v·ªÅ b·ªô m·∫∑c ƒë·ªãnh.
    Kh√¥ng spam WARN n·ªØa.
    """
    if not os.path.exists(path):
        return default_standards()

    with open(path, "r", encoding="utf-8") as f:
        lines = f.readlines()

    standards: Dict[str, Standard] = {}
    code = None
    name = ""
    buf: List[str] = []

    for line in lines:
        s = line.strip()
        if s.startswith("## "):
            # L∆∞u block c≈©
            if code:
                standards[code] = Standard(
                    code=code,
                    name=name,
                    description="\n".join(buf).strip(),
                )
            after = s[3:].strip()
            if "‚Äì" in after:
                parts = after.split("‚Äì", 1)
                code = parts[0].strip()
                name = parts[1].strip()
            else:
                parts = after.split()
                code = parts[0].strip()
                name = parts[0].strip()
            buf = []
        else:
            if code:
                buf.append(line.rstrip())

    if code:
        standards[code] = Standard(
            code=code,
            name=name,
            description="\n".join(buf).strip(),
        )

    if not standards:
        return default_standards()
    return standards


def load_chuan_dau_ra_raw(path: str, standards: Dict[str, Standard]) -> str:
    """
    Raw text ƒë·ªÉ nh√©t v√†o prompt AI. N·∫øu c√≥ file th√¨ d√πng file, kh√¥ng th√¨ build t·ª´ dict.
    """
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return f.read()

    parts = ["# Chu·∫©n ƒë·∫ßu ra To√°n 9 (m·∫∑c ƒë·ªãnh)"]
    for s in standards.values():
        parts.append(f"## {s.code} ‚Äì {s.name}")
        parts.append(s.description)
    return "\n\n".join(parts)


STANDARDS: Dict[str, Standard] = parse_chuan_dau_ra_md(CHUAN_DAU_RA_FILE)
CHUAN_DAU_RA_TEXT: str = load_chuan_dau_ra_raw(CHUAN_DAU_RA_FILE, STANDARDS)

# ========================
#  DETECT CHU·∫®N T·ª™ TEXT
# ========================
def detect_standards_from_text(text: str) -> List[str]:
    t = text.lower()
    found: List[str] = []

    KEYWORDS = {
        "T1": ["ucln", "bcnn", "l≈©y th·ª´a", "s·ªë m≈©", "luy thua"],
        "T2": ["ph·∫ßn trƒÉm", "%", "t·ªâ l·ªá", "t·ª∑ l·ªá", "gi·∫£m gi√°"],
        "T3": ["g√≥c", "tam gi√°c", "ch·ª©ng minh", "tam giac"],
        "T4": ["cƒÉn b·∫≠c hai", "cƒÉn b·∫≠c 2", "sqrt"],
        "T5": ["ph∆∞∆°ng tr√¨nh b·∫≠c nh·∫•t", "pt b·∫≠c nh·∫•t"],
        "T6": ["h·ªá ph∆∞∆°ng tr√¨nh", "hpt"],
        "T7": ["b·∫•t ph∆∞∆°ng tr√¨nh"],
        "T8": ["h√†m s·ªë", "ƒë·ªì th·ªã", "graph"],
        "T9": ["tam gi√°c vu√¥ng", "pytago", "pythagore"],
        "T10": ["ƒë∆∞·ªùng tr√≤n", "cung", "g√≥c n·ªôi ti·∫øp"],
        "T11": ["ti·∫øp tuy·∫øn"],
        "T12": ["h√¨nh tr·ª•", "h√¨nh n√≥n", "h√¨nh c·∫ßu"],
        "T13": ["t·∫ßn s·ªë", "b·∫£ng t·∫ßn s·ªë", "th·ªëng k√™"],
        "T14": ["x√°c su·∫•t"],
        "T15": ["b√†i to√°n th·ª±c t·∫ø", "th·ª±c t·∫ø", "b·ªëi c·∫£nh th·ª±c t·∫ø"],
    }

    for code, keywords in KEYWORDS.items():
        if any(k in t for k in keywords):
            found.append(code)

    if not found:
        found.append("T1")

    # l·ªçc theo b·ªô STANDARDS ƒëang c√≥
    return [x for x in found if x in STANDARDS]


# ========================
#  BASIC ROUTES
# ========================
@app.get("/", response_class=HTMLResponse)
def root():
    if os.path.exists(INDEX_FILE):
        with open(INDEX_FILE, "r", encoding="utf-8") as f:
            return f.read()
    return HTMLResponse(
        "<h1>K9 Math AI Assistant</h1><p>Kh√¥ng t√¨m th·∫•y index.html</p>",
        status_code=500,
    )


@app.get("/api/health")
def api_health():
    return {
        "status": "ok",
        "standards_loaded": list(STANDARDS.keys()),
        "has_chuan_dau_ra_file": os.path.exists(CHUAN_DAU_RA_FILE),
    }


# ========================
#  CHAT ‚Äì GI·∫¢I TO√ÅN (lu√¥n tr·∫£ 200, kh√¥ng n√©m 500 ra ngo√†i)
# ========================
@app.post("/chat/message", response_model=ChatResponse)
async def chat_message(req: ChatRequest):
    standards_text = "\n".join(
        f"{s.code}: {s.name}\n{s.description}\n" for s in STANDARDS.values()
    )

    system_prompt = (
        "B·∫°n l√† Tr·ª£ l√Ω To√°n 9 AI d√†nh cho h·ªçc sinh.\n"
        "- Gi·∫£i b√†i t·∫≠p r√µ r√†ng, t·ª´ng b∆∞·ªõc, ƒë√∫ng ch∆∞∆°ng tr√¨nh To√°n 9.\n"
        "- B√°m s√°t b·ªô chu·∫©n T1‚ÄìT15 do gi√°o vi√™n cung c·∫•p.\n"
        "- D√πng LaTeX v·ªõi $...$ (inline) v√† $$...$$ (block) cho c√¥ng th·ª©c.\n"
        "- Sau khi gi·∫£i xong, h√£y:\n"
        "  ‚Ä¢ N√≥i ng·∫Øn g·ªçn h·ªçc sinh v·ª´a √¥n l·∫°i n·ªôi dung g√¨ (c√≥ th·ªÉ nh·∫Øc T1‚ÄìT15 n·∫øu ph√π h·ª£p).\n"
        "  ‚Ä¢ G·ª£i √Ω 1‚Äì3 ho·∫°t ƒë·ªông h·ªçc ti·∫øp theo.\n"
        "  ‚Ä¢ C√≥ th·ªÉ g·ª£i √Ω r·∫±ng b·∫°n c√≥ th·ªÉ t·∫°o quiz luy·ªán t·∫≠p.\n"
        "- Tr√¨nh b√†y g·ªçn, kh√¥ng th·ª´a d√≤ng tr·∫Øng.\n\n"
        "D∆∞·ªõi ƒë√¢y l√† t√≥m t·∫Øt c√°c chu·∫©n T1‚ÄìT15:\n"
        f"{standards_text}"
    )

    messages = [{"role": "system", "content": system_prompt}]
    messages += [{"role": m.role, "content": m.content} for m in req.messages]

    last_user_msg = ""
    for m in reversed(req.messages):
        if m.role == "user":
            last_user_msg = m.content
            break

    try:
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
        )
        reply = completion.choices[0].message.content.strip()
    except Exception as e:
        # Kh√¥ng n√©m 500 ra ngo√†i, tr·∫£ lu√¥n text l·ªói
        reply = (
            "Hi·ªán t·∫°i server g·∫∑p l·ªói khi g·ªçi m√¥ h√¨nh AI n√™n m√¨nh t·∫°m th·ªùi "
            "kh√¥ng gi·∫£i ƒë∆∞·ª£c b√†i to√°n n√†y.\n\n"
            "Ng∆∞·ªùi qu·∫£n tr·ªã c√≥ th·ªÉ ki·ªÉm tra l·∫°i c·∫•u h√¨nh OPENAI_API_KEY, "
            "model, ho·∫∑c k·∫øt n·ªëi m·∫°ng c·ªßa server.\n"
            f"(Chi ti·∫øt k·ªπ thu·∫≠t: {e})"
        )

    detected = detect_standards_from_text(last_user_msg)
    return ChatResponse(reply=reply, standards=detected)


# ========================
#  CLASSIFY (DEV)
# ========================
@app.post("/api/classify", response_model=ClassifyResponse)
async def api_classify(req: ClassifyRequest):
    detected = detect_standards_from_text(req.text)
    return ClassifyResponse(standards=detected)


# ========================
#  QUIZ SINH B·ªûI AI
# ========================
def generate_quiz_with_ai(mode: str, n: int = 10) -> List[QuizQuestion]:
    """
    G·ªçi OpenAI ƒë·ªÉ sinh n c√¢u h·ªèi tr·∫Øc nghi·ªám d·ª±a tr√™n CHU·∫®N ƒê·∫¶U RA.
    mode: 'input' (ƒë·∫ßu v√†o), 'output' (ƒë·∫ßu ra / c·ªßng c·ªë).
    """
    if not os.environ.get("OPENAI_API_KEY"):
        raise RuntimeError("Thi·∫øu OPENAI_API_KEY, kh√¥ng sinh quiz AI ƒë∆∞·ª£c.")

    # Gi·ªõi h·∫°n ƒë·ªô d√†i chu·∫©n ƒë·∫ßu ra cho g·ªçn prompt
    chuan_text = CHUAN_DAU_RA_TEXT
    if len(chuan_text) > 12000:
        chuan_text = chuan_text[:12000]

    difficulty_note = (
        "T·∫°o c√¢u h·ªèi ·ªü m·ª©c c∆° b·∫£n‚Äìtrung b√¨nh, ph√π h·ª£p ki·ªÉm tra ƒë·∫ßu v√†o."
        if mode == "input"
        else "T·∫°o c√¢u h·ªèi ·ªü m·ª©c v·∫≠n d·ª•ng‚Äìn√¢ng cao nh·∫π, ph√π h·ª£p ki·ªÉm tra ƒë·∫ßu ra, c·ªßng c·ªë ki·∫øn th·ª©c."
    )

    system_prompt = (
        "B·∫°n l√† gi√°o vi√™n To√°n 9, chuy√™n so·∫°n ƒë·ªÅ tr·∫Øc nghi·ªám b√°m s√°t chu·∫©n ƒë·∫ßu ra T1‚ÄìT15.\n"
        "B·∫°n s·∫Ω sinh ra b·ªô c√¢u h·ªèi tr·∫Øc nghi·ªám b·ªën l·ª±a ch·ªçn A‚ÄìD, ƒë√∫ng ch∆∞∆°ng tr√¨nh, r√µ r√†ng, kh√¥ng ƒë√°nh ƒë·ªë.\n"
    )

    user_prompt = f"""
Chu·∫©n ƒë·∫ßu ra To√°n 9:

{chuan_text}

Nhi·ªám v·ª•:

- {difficulty_note}
- M·ªói c√¢u h·ªèi l√† 1 b√†i tr·∫Øc nghi·ªám 4 l·ª±a ch·ªçn A, B, C, D.
- M·ªói c√¢u g·∫Øn v·ªõi 1‚Äì3 chu·∫©n trong s·ªë T1‚ÄìT15 (v√≠ d·ª• ["T1"], ["T3","T9"]...).
- Tuy·ªát ƒë·ªëi kh√¥ng d√πng ki·∫øn th·ª©c ngo√†i ch∆∞∆°ng tr√¨nh To√°n 9.

Y√™u c·∫ßu xu·∫•t:

Tr·∫£ v·ªÅ *DUY NH·∫§T* m·ªôt JSON h·ª£p l·ªá theo m·∫´u:

{{
  "questions": [
    {{
      "id": 1,
      "text": "N·ªôi dung c√¢u h·ªèi...",
      "options": ["Ph∆∞∆°ng √°n A", "Ph∆∞∆°ng √°n B", "Ph∆∞∆°ng √°n C", "Ph∆∞∆°ng √°n D"],
      "correct_index": 0,
      "standards": ["T1","T2"]
    }},
    ...
  ]
}}

- Sinh ƒë√∫ng {n} c√¢u h·ªèi.
- "correct_index" l√† s·ªë 0‚Äì3 t∆∞∆°ng ·ª©ng A‚ÄìD.
- "standards" ch·ªâ bao g·ªìm c√°c m√£ trong: {list(STANDARDS.keys())}.
"""

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
    )
    raw = completion.choices[0].message.content.strip()

    # B√≥c JSON
    try:
        if "```" in raw:
            raw = raw.split("```", 2)[1]
            raw = raw.replace("json", "", 1).strip()
        data = json.loads(raw)
    except Exception as e:
        raise RuntimeError(f"L·ªói parse JSON quiz t·ª´ OpenAI: {e}")

    questions_data = data.get("questions", [])
    questions: List[QuizQuestion] = []
    seen_ids = set()

    for i, q in enumerate(questions_data):
        try:
            q_id = int(q.get("id") or (i + 1))
            if q_id in seen_ids:
                q_id = max(seen_ids) + 1
            seen_ids.add(q_id)

            text = str(q.get("text", "")).strip()
            options = [str(x) for x in (q.get("options") or [])]
            if len(options) != 4:
                continue
            ci = int(q.get("correct_index", 0))
            if ci < 0 or ci > 3:
                continue
            standards = [s for s in (q.get("standards") or []) if s in STANDARDS]

            if not text:
                continue

            questions.append(
                QuizQuestion(
                    id=q_id,
                    text=text,
                    options=options,
                    correct_index=ci,
                    standards=standards or ["T1"],
                )
            )
        except Exception:
            continue

    if not questions:
        raise RuntimeError("Kh√¥ng sinh ƒë∆∞·ª£c c√¢u h·ªèi h·ª£p l·ªá n√†o t·ª´ OpenAI.")
    if len(questions) > n:
        questions = questions[:n]

    return questions


@app.get("/api/input_quiz", response_model=QuizResponse)
async def api_input_quiz():
    """
    Sinh ƒë·ªÅ ki·ªÉm tra ƒë·∫ßu v√†o. N·∫øu ƒë√£ c√≥ ƒë·ªÅ trong cache th√¨ tr·∫£ l·∫°i y nguy√™n,
    ch·ªâ khi reset (POST /api/reset_quiz) m·ªõi sinh ƒë·ªÅ m·ªõi.
    """
    try:
        if not QUIZ_CACHE["input"]:
            QUIZ_CACHE["input"] = generate_quiz_with_ai("input", n=10)
        return QuizResponse(questions=QUIZ_CACHE["input"])
    except Exception as e:
        raise HTTPException(500, f"L·ªói sinh ƒë·ªÅ ki·ªÉm tra ƒë·∫ßu v√†o b·∫±ng AI: {e}")


@app.get("/api/output_quiz", response_model=QuizResponse)
async def api_output_quiz():
    """
    Sinh ƒë·ªÅ ki·ªÉm tra ƒë·∫ßu ra / c·ªßng c·ªë. Cache theo mode 'output'.
    """
    try:
        if not QUIZ_CACHE["output"]:
            QUIZ_CACHE["output"] = generate_quiz_with_ai("output", n=10)
        return QuizResponse(questions=QUIZ_CACHE["output"])
    except Exception as e:
        raise HTTPException(500, f"L·ªói sinh ƒë·ªÅ ki·ªÉm tra ƒë·∫ßu ra b·∫±ng AI: {e}")


class ResetQuizRequest(BaseModel):
    mode: str = "all"  # 'input', 'output', 'all'


@app.post("/api/reset_quiz")
async def api_reset_quiz(req: ResetQuizRequest):
    """
    Reset ƒë·ªÅ quiz tr√™n server. ƒê∆∞·ª£c g·ªçi khi ng∆∞·ªùi d√πng b·∫•m 'L√†m l·∫°i ƒë·ªÅ m·ªõi'.
    """
    mode = (req.mode or "all").lower().strip()
    if mode in ("input", "output"):
        QUIZ_CACHE[mode] = []
    else:
        for k in QUIZ_CACHE.keys():
            QUIZ_CACHE[k] = []

    return {"status": "ok", "mode": mode}


# ========================
#  FILE PARSE (PDF/TXT)
# ========================
@app.post("/file/parse")
async def parse_file(file: UploadFile = File(...)):
    name = file.filename

    try:
        if name.lower().endswith(".pdf"):
            reader = PdfReader(file.file)
            pages = [page.extract_text() or "" for page in reader.pages]
            content = "\n\n".join(pages)
        else:
            raw = await file.read()
            content = raw.decode("utf-8", errors="ignore")

        if len(content) > 8000:
            content = content[:8000]

        return {"filename": name, "content": content}
    except Exception as e:
        raise HTTPException(400, f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file: {e}")
